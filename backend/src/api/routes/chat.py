"""Chat API with StreamingEngine - SSE streaming support."""
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
import asyncio
from typing import AsyncGenerator

from ...db import AsyncSessionLocal
from ...services import ChatService
from ...agent import create_agent
from ...models.schema import ChatRequest
from ...utils.logger import get_logger
from ...utils.streaming_engine import (
    StreamingEngine,
    SessionStatus,
    ToolStatus,
    DataType,
    ErrorType
)

router = APIRouter()
logger = get_logger(__name__)


async def generate_sse_response(
    session_id: str,
    content: str,
    file_ids: list[str] | None
) -> AsyncGenerator[str, None]:
    """
    ä½¿ç”¨ StreamingEngine ç”Ÿæˆ SSE æ ¼å¼çš„æµå¼å“åº”

    æµç¨‹ï¼š
    1. åˆ›å»º StreamingEngine å®ä¾‹
    2. åˆ›å»ºäº‹ä»¶é˜Ÿåˆ—ï¼ˆç”¨äºå·¥å…·è°ƒç”¨äº‹ä»¶ï¼‰
    3. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å¹¶å…³è”æ–‡ä»¶
    4. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå†å²æ¶ˆæ¯ï¼‰
    5. åˆ›å»º Agent å¹¶ä¼ å…¥äº‹ä»¶é˜Ÿåˆ—
    6. å¹¶å‘å¤„ç† Agent æµå¼è¾“å‡ºå’Œäº‹ä»¶é˜Ÿåˆ—
    7. ä¿å­˜ assistant æ¶ˆæ¯
    8. å‘é€ä¼šè¯ç»“æŸäº‹ä»¶

    Args:
        session_id: ä¼šè¯ ID
        content: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
        file_ids: å…³è”çš„æ–‡ä»¶ IDs

    Yields:
        SSE æ ¼å¼çš„äº‹ä»¶å­—ç¬¦ä¸²
    """
    # åˆ›å»ºæµå¼è¾“å‡ºå¼•æ“
    engine = StreamingEngine()

    # åˆ›å»ºäº‹ä»¶é˜Ÿåˆ—ï¼ˆç”¨äºå·¥å…·è°ƒç”¨äº‹ä»¶ï¼‰
    event_queue = asyncio.Queue()

    async with AsyncSessionLocal() as db:
        try:
            service = ChatService(db)

            # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨
            session = await service.get_session(session_id)
            if not session:
                yield engine.emit_error(
                    ErrorType.VALIDATION,
                    "ä¼šè¯ä¸å­˜åœ¨",
                    recoverable=False
                )
                yield engine.emit_session_end(SessionStatus.ERROR)
                return

            # å‘é€ä¼šè¯å¼€å§‹äº‹ä»¶
            yield engine.emit_session_start(session_id)

            # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å¹¶å…³è”æ–‡ä»¶
            user_msg = await service.create_user_message(
                session_id=session_id,
                content=content,
                file_ids=file_ids
            )

            logger.info(
                f"[chat] åˆ›å»ºç”¨æˆ·æ¶ˆæ¯: {user_msg.message_id}, "
                f"å…³è”æ–‡ä»¶: {file_ids or []}"
            )

            # ç´¯ç§¯å†…å®¹ï¼ˆç”¨äºä¿å­˜ï¼‰
            accumulated_content = ""
            tool_calls_metadata = []
            data_blocks_metadata = []

            # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå†å²æ¶ˆæ¯ï¼‰
            messages = await service.get_messages(session_id, limit=20)
            context_messages = [
                {"role": msg.role, "content": msg.content}
                for msg in messages
            ]

            # åˆ›å»º Agentï¼ˆä¼ å…¥äº‹ä»¶é˜Ÿåˆ—ï¼‰
            agent = create_agent(
                session_id=session_id,
                db=db,
                event_queue=event_queue
            )

            logger.info(
                f"[chat] è°ƒç”¨ Agentï¼Œä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°: {len(context_messages)}, "
                f"å½“å‰è¾“å…¥: {content[:50]}"
            )

            # æµå¼è°ƒç”¨ Agent
            response = agent.arun(input=content, stream=True)

            # æ ‡è®° Agent æµå¼å“åº”æ˜¯å¦ç»“æŸ
            agent_done = False

            async def process_agent_stream():
                """å¤„ç† Agent æµå¼å“åº”"""
                nonlocal accumulated_content, agent_done
                logger.info("[process_agent_stream] ğŸš€ å¼€å§‹å¤„ç† Agent æµå¼å“åº”")
                chunk_count = 0
                try:
                    logger.info("[process_agent_stream] ğŸ“¡ å‡†å¤‡è¿­ä»£å“åº”æµ...")
                    async for chunk in response:
                        chunk_count += 1
                        logger.info(f"[process_agent_stream] ğŸ“¦ æ”¶åˆ° chunk #{chunk_count}: type={type(chunk)}, has_content={hasattr(chunk, 'content')}")

                        # æ‰“å° chunk çš„å±æ€§
                        if hasattr(chunk, '__dict__'):
                            logger.debug(f"[process_agent_stream] chunk å±æ€§: {chunk.__dict__}")

                        # æ–‡æœ¬å†…å®¹ - å‘é€ä¸ºæ­£æ–‡å†…å®¹
                        if hasattr(chunk, "content") and chunk.content:
                            logger.info(f"[process_agent_stream] âœ… æœ‰å†…å®¹: {chunk.content[:100]}...")
                            accumulated_content += chunk.content

                            # å°† Agent çš„æ–‡æœ¬è¾“å‡ºä½œä¸ºæ­£æ–‡å†…å®¹å‘é€
                            yield engine.emit_content(
                                content=chunk.content,
                                format="markdown",
                                is_complete=False
                            )
                        else:
                            logger.warning(f"[process_agent_stream] âš ï¸  chunk æ²¡æœ‰ content æˆ– content ä¸ºç©º")

                    logger.info(f"[process_agent_stream] âœ… æµå¼å“åº”ç»“æŸï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ª chunks")
                except Exception as e:
                    logger.error(f"[process_agent_stream] âŒ å¤„ç†æµæ—¶å‡ºé”™: {e}", exc_info=True)
                finally:
                    agent_done = True
                    logger.info("[process_agent_stream] ğŸ è®¾ç½® agent_done=Trueï¼Œå‘é€å®Œæˆäº‹ä»¶")
                    await event_queue.put({"event_type": "agent_done"})

            # å¯åŠ¨ Agent æµå¼å¤„ç†ä»»åŠ¡
            agent_generator = process_agent_stream()

            # åŒæ—¶å¤„ç†ä¸¤ä¸ªæµï¼šAgent è¾“å‡ºæµå’Œäº‹ä»¶é˜Ÿåˆ—
            try:
                # ä½¿ç”¨æ ‡å¿—è·Ÿè¸ªå“ªä¸ªæµè¿˜åœ¨è¿è¡Œ
                agent_streaming = True
                loop_count = 0
                agent_task_running = None  # è·Ÿè¸ªå½“å‰è¿è¡Œçš„ agent_task

                logger.info("[main_loop] ğŸ”„ å¼€å§‹ä¸»å¾ªç¯ï¼ŒåŒæ—¶å¤„ç† Agent æµå’Œäº‹ä»¶é˜Ÿåˆ—")

                while agent_streaming or not event_queue.empty():
                    loop_count += 1
                    logger.debug(f"[main_loop] å¾ªç¯ #{loop_count}, agent_streaming={agent_streaming}, queue_empty={event_queue.empty()}")

                    # åˆ›å»ºä¸¤ä¸ªä»»åŠ¡
                    tasks = []

                    # Agent è¾“å‡ºæµä»»åŠ¡ - åªæœ‰åœ¨æ²¡æœ‰ä»»åŠ¡è¿è¡Œæ—¶æ‰åˆ›å»ºæ–°çš„
                    if agent_streaming and agent_task_running is None:
                        agent_task_running = asyncio.create_task(
                            anext(agent_generator, None)
                        )
                        logger.debug(f"[main_loop] åˆ›å»ºæ–°çš„ agent_task")

                    if agent_task_running is not None:
                        tasks.append(agent_task_running)

                    # äº‹ä»¶é˜Ÿåˆ—ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼Œé¿å…æ°¸ä¹…ç­‰å¾…ï¼‰
                    try:
                        queue_task = asyncio.create_task(
                            asyncio.wait_for(event_queue.get(), timeout=0.1)
                        )
                        tasks.append(queue_task)
                        logger.debug(f"[main_loop] æ·»åŠ  queue_task")
                    except asyncio.TimeoutError:
                        pass

                    if not tasks:
                        logger.info("[main_loop] æ²¡æœ‰ä»»åŠ¡ï¼Œé€€å‡ºå¾ªç¯")
                        break

                    # ç­‰å¾…ä»»æ„ä»»åŠ¡å®Œæˆ
                    logger.debug(f"[main_loop] ç­‰å¾… {len(tasks)} ä¸ªä»»åŠ¡å®Œæˆ...")
                    done, pending = await asyncio.wait(
                        tasks,
                        return_when=asyncio.FIRST_COMPLETED
                    )
                    logger.debug(f"[main_loop] {len(done)} ä¸ªä»»åŠ¡å®Œæˆï¼Œ{len(pending)} ä¸ªä»»åŠ¡å¾…å¤„ç†")

                    # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                    for task in done:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ agent_task å®Œæˆäº†
                        if task is agent_task_running:
                            agent_task_running = None
                            logger.debug("[main_loop] agent_task å·²å®Œæˆï¼Œé‡ç½®ä¸º None")

                        try:
                            result = task.result()
                            logger.debug(f"[main_loop] ä»»åŠ¡ç»“æœ: type={type(result)}, value={str(result)[:200] if result else 'None'}")

                            # å¦‚æœæ˜¯ Agent è¾“å‡º
                            if result and isinstance(result, str):
                                logger.info(f"[main_loop] ğŸ“¤ Agent è¾“å‡º (str): {result[:100]}...")
                                yield result

                            # å¦‚æœæ˜¯ Agent å®Œæˆä¿¡å·
                            elif result is None and agent_streaming:
                                logger.info("[main_loop] ğŸ Agent å®Œæˆä¿¡å· (None)")
                                agent_streaming = False

                            # å¦‚æœæ˜¯äº‹ä»¶é˜Ÿåˆ—çš„äº‹ä»¶
                            elif result and isinstance(result, dict):
                                event = result
                                logger.info(f"[main_loop] ğŸ“¨ äº‹ä»¶é˜Ÿåˆ—äº‹ä»¶: {event.get('event_type')}")

                                # Agent å®Œæˆ
                                if event.get("event_type") == "agent_done":
                                    agent_streaming = False
                                    continue

                                # å·¥å…·è°ƒç”¨å¼€å§‹
                                elif event.get("event_type") == "tool_call_start":
                                    sse_event = engine.emit_tool_call_start(
                                        tool_id=event["tool_id"],
                                        tool_name=event["tool_name"],
                                        description=event["description"],
                                        arguments=event.get("arguments")
                                    )
                                    yield sse_event

                                    # è®°å½•åˆ°å…ƒæ•°æ®
                                    tool_calls_metadata.append({
                                        "tool_id": event["tool_id"],
                                        "tool_name": event["tool_name"],
                                        "description": event["description"]
                                    })

                                # å·¥å…·è°ƒç”¨ç»“æŸ
                                elif event.get("event_type") == "tool_call_end":
                                    status = ToolStatus.SUCCESS if event["status"] == "success" else ToolStatus.FAILED
                                    sse_event = engine.emit_tool_call_end(
                                        tool_id=event["tool_id"],
                                        status=status,
                                        result=event.get("result"),
                                        error=event.get("error"),
                                        duration_ms=event.get("duration_ms")
                                    )
                                    yield sse_event

                                # å†…å®¹äº‹ä»¶
                                elif event.get("event_type") == "content":
                                    content_text = event["content"]
                                    accumulated_content += content_text
                                    sse_event = engine.emit_content(
                                        content=content_text,
                                        format=event.get("format", "markdown"),
                                        is_complete=event.get("is_complete", False)
                                    )
                                    yield sse_event

                                # æ•°æ®äº‹ä»¶
                                elif event.get("event_type") == "data":
                                    sse_event = engine.emit_data(
                                        data_type=DataType(event["data_type"]),
                                        data=event["data"],
                                        metadata=event.get("metadata")
                                    )
                                    yield sse_event

                                    # è®°å½•åˆ°å…ƒæ•°æ®
                                    data_blocks_metadata.append({
                                        "data_type": event["data_type"],
                                        "name": event["data"].get("name", "æœªå‘½åæ•°æ®")
                                    })

                        except asyncio.TimeoutError:
                            # é˜Ÿåˆ—è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡
                            continue
                        except Exception as e:
                            logger.error(f"[chat] å¤„ç†ä»»åŠ¡ç»“æœæ—¶å‡ºé”™: {e}", exc_info=True)
                            continue

                    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡ï¼ˆé™¤äº† agent_taskï¼‰
                    for task in pending:
                        if task is not agent_task_running:
                            task.cancel()

            finally:
                # ç¡®ä¿ Agent ä»»åŠ¡å®Œæˆ
                try:
                    async for _ in agent_generator:
                        pass
                except StopAsyncIteration:
                    pass

            # ä¿å­˜ assistant æ¶ˆæ¯
            metadata = None
            if tool_calls_metadata or data_blocks_metadata:
                metadata = {}
                if tool_calls_metadata:
                    metadata["tool_calls"] = tool_calls_metadata
                if data_blocks_metadata:
                    metadata["data_blocks"] = data_blocks_metadata

            await service.create_assistant_message(
                session_id=session_id,
                content=accumulated_content,
                metadata=metadata
            )

            # å‘é€ä¼šè¯ç»“æŸäº‹ä»¶
            yield engine.emit_session_end(
                SessionStatus.COMPLETED,
                summary={
                    "tool_calls": len(tool_calls_metadata),
                    "data_blocks": len(data_blocks_metadata),
                    "content_length": len(accumulated_content)
                }
            )

            logger.info(
                f"[chat] æ¶ˆæ¯å®Œæˆï¼Œsession={session_id}, "
                f"å›å¤é•¿åº¦={len(accumulated_content)}, "
                f"å·¥å…·è°ƒç”¨={len(tool_calls_metadata)}, "
                f"æ•°æ®å—={len(data_blocks_metadata)}"
            )

        except ValueError as e:
            # ä¸šåŠ¡é€»è¾‘é”™è¯¯
            logger.warning(f"[chat] ä¸šåŠ¡é”™è¯¯: {e}")
            yield engine.emit_error(
                ErrorType.VALIDATION,
                str(e),
                recoverable=False
            )
            yield engine.emit_session_end(SessionStatus.ERROR)

        except Exception as e:
            # ç³»ç»Ÿé”™è¯¯
            logger.error(f"[chat] ç³»ç»Ÿé”™è¯¯: {e}", exc_info=True)
            await db.rollback()
            yield engine.emit_error(
                ErrorType.SYSTEM,
                f"ç³»ç»Ÿé”™è¯¯: {str(e)}",
                details={"exception": str(e)},
                recoverable=False
            )
            yield engine.emit_session_end(SessionStatus.ERROR)


@router.post("/chat")
async def chat(request: ChatRequest):
    """
    å‘é€æ¶ˆæ¯å¹¶è·å–æµå¼å“åº”ï¼ˆä½¿ç”¨ StreamingEngineï¼‰

    ä¸»è¦æ”¹è¿›ï¼š
    - ç»Ÿä¸€çš„äº‹ä»¶æ ¼å¼å’Œç±»å‹
    - å®Œæ•´çš„å…ƒæ•°æ®æ”¯æŒ
    - æ›´å¥½çš„é”™è¯¯å¤„ç†
    - è¯¦ç»†çš„æ—¥å¿—è®°å½•

    Args:
        request: åŒ…å« session_idã€contentã€file_ids

    Returns:
        SSE æµå¼å“åº”
    """
    return StreamingResponse(
        generate_sse_response(
            session_id=request.session_id,
            content=request.content,
            file_ids=request.file_ids
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )
